<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="S3 Automatic Image Compression" />
<meta name="author" content="Pete Graham" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Using S3 notifications sent to SQS" />
<meta property="og:description" content="Using S3 notifications sent to SQS" />
<link rel="canonical" href="https://petegraham.com/pr-preview/pr-13/s3-automatic-image-compression/" />
<meta property="og:url" content="https://petegraham.com/pr-preview/pr-13/s3-automatic-image-compression/" />
<meta property="og:site_name" content="Pete Graham - CTO" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2015-07-29T17:25:43+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="S3 Automatic Image Compression" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Pete Graham"},"dateModified":"2015-07-29T17:25:43+00:00","datePublished":"2015-07-29T17:25:43+00:00","description":"Using S3 notifications sent to SQS","headline":"S3 Automatic Image Compression","mainEntityOfPage":{"@type":"WebPage","@id":"https://petegraham.com/pr-preview/pr-13/s3-automatic-image-compression/"},"url":"https://petegraham.com/pr-preview/pr-13/s3-automatic-image-compression/"}</script>
<!-- End Jekyll SEO tag -->

  <title>Pete Graham - CTO - S3 Automatic Image Compression</title>
  <link rel="apple-touch-icon" href='/pr-preview/pr-13/assets/images/apple-touch-icon.png'>
  <link rel="icon" type="image/svg+xml" href='/pr-preview/pr-13/assets/images/favicon.svg'>
  <link rel="icon" href='/pr-preview/pr-13/assets/images/favicon.ico'>
  <link rel="manifest" href='/pr-preview/pr-13/assets/images/site.webmanifest'>
  <link rel="icon" type="image/png" sizes="192x192" href='/pr-preview/pr-13/assets/images/web-app-manifest-192x192.png'>
  <link rel="icon" type="image/png" sizes="512x512" href='/pr-preview/pr-13/assets/images/web-app-manifest-512x512.png'>
  <link rel="stylesheet" href='/pr-preview/pr-13/assets/css/style.css'>
  <link rel="alternate" type="application/rss+xml" title="My Blog" href='/pr-preview/pr-13/rss.xml'>
  <link rel="stylesheet" href='/pr-preview/pr-13/assets/css/highlight.css'>
</head>
<body>

  <nav class="main-nav">
  <div class="nav-content">
    <a class="brand" href='/pr-preview/pr-13/'>petegraham.com</a>
    <a href='/pr-preview/pr-13/blog/'>Articles</a>
    <a href='/pr-preview/pr-13/TIL/'>TIL </a>
    <a href='/pr-preview/pr-13/'>About</a>
  </div>
</nav>


  

  <section id="wrapper" class="">
    <article class="post">
    <header>
        <h1>S3 Automatic Image Compression</h1>
    </header>
    <section id="post-body">
        <p>I wanted a system that could automatically apply lossless compression to images uploaded to an S3 bucket. Here’s how it works:</p>

<ol>
  <li>User uploads a file to the S3 bucket.</li>
  <li>S3 bucket notifications send a messages to SQS.</li>
  <li>Python script monitors the queue for new messages.</li>
  <li>When a new message is received the image file is downloaded locally.</li>
  <li>Local file is compressed with mozjpeg.</li>
  <li>The original S3 file is then replaced with the compressed version.</li>
</ol>

<p>The code for the Python script is on Github <a href="https://github.com/pxg/S3-image-compression">https://github.com/pxg/S3-image-compression</a>.</p>

<p>The motivation behind this project was to experiment with the S3 bucket notification system and Python 3. I wanted to see if working with this system would provide a clean solution for file processing tasks.</p>

<p>I think this solution could be particularly useful to use with a CMS which has the ability to write image files to S3 but doesn’t provide image compression.</p>

<p>##Getting set-up on AWS</p>

<p>The trickiest part of was getting the different components configured on AWS, so I’ve written this guide.</p>

<p>###1. Create S3 Bucket
Use the <a href="https://console.aws.amazon.com/s3/home">AWS S3 console</a> to create your new bucket. <a href="https://alestic.com/2014/12/s3-bucket-notification-to-sqssns-on-object-creation/">This article</a> has some useful techniques for creating AWS items if you’d prefer to just use the command line.</p>

<p>###2. Create an SQS instance
Use the <a href="https://eu-west-1.console.aws.amazon.com/sqs/home">AWS SQS console</a> to create a new queue. Next set-up queue’s permissions. The fastest (but least secure) way is to allow “Everybody” and “All SQS Actions”.</p>

<p><a href="/assets/images/posts/SQS.png"><img src="/assets/images/posts/SQS_thumb.png" alt="AWS SQS UI" /></a></p>

<p>###3. Configure S3 bucket notifications to write to the SQS
Go to the <a href="https://console.aws.amazon.com/s3/home">AWS S3 console</a> and select your bucket. Next click the properties button on the top right. Look for the Event section and enter:</p>

<ul>
  <li>Events: ObjectCreated (All)</li>
  <li>SendTo: SQS queue</li>
  <li>SQS Queue: your-queue-name</li>
</ul>

<p><a href="/assets/images/posts/S3_notifications.png"><img src="/assets/images/posts/S3_notifications_thumb.png" alt="AWS S3 UI" /></a></p>

<h3 id="4-create-an-iam-user">4. Create an IAM User</h3>
<p>Use the <a href="https://console.aws.amazon.com/iam/home#users">AWS user console</a> to create a new IAM user. Next give them write access to the S3 bucket. To do this create a new policy and use the following for the policy document:</p>

<figure class="highlight"><pre><code class="language-json" data-lang="json"><span class="p">{</span><span class="w">
    </span><span class="nl">"Statement"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"Action"</span><span class="p">:</span><span class="w"> </span><span class="s2">"s3:*"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"Effect"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Allow"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"Resource"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
                </span><span class="s2">"arn:aws:s3:::your-bucket-name"</span><span class="p">,</span><span class="w">
                </span><span class="s2">"arn:aws:s3:::ysour-bucket-name/*"</span><span class="w">
            </span><span class="p">]</span><span class="w">
        </span><span class="p">}</span><span class="w">
    </span><span class="p">]</span><span class="w">
</span><span class="p">}</span></code></pre></figure>

<p>Of course replace “your-bucket-name” with the real value, you’re using.</p>

<p>###5. Give the User access to read/write SQS
The simplest way to do this is attach the policy “AmazonSQSFullAccess” to the user. In a production system you’d want to lock the users access down further.</p>

<p>###6. Give user access to get information about their account
The reasons for this will be explained next. You’ll need to add this policy:</p>

<figure class="highlight"><pre><code class="language-json" data-lang="json"><span class="p">{</span><span class="w">
    </span><span class="nl">"Version"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2012-10-17"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"Statement"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"Sid"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Stmt1438081733000"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"Effect"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Allow"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"Action"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
                </span><span class="s2">"iam:GetUser"</span><span class="w">
            </span><span class="p">],</span><span class="w">
            </span><span class="nl">"Resource"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
                </span><span class="s2">"arn:aws:iam::239820892130:user/s3-image-resizer"</span><span class="w">
            </span><span class="p">]</span><span class="w">
        </span><span class="p">}</span><span class="w">
    </span><span class="p">]</span><span class="w">
</span><span class="p">}</span></code></pre></figure>

<p>You’ll need to change the resource to match your user. Thankfully the Users ARN is easy to find. Go to the <a href="https://console.aws.amazon.com/iam/home#users">AWS user console</a>, select your user, the information is in the summary.</p>

<p><a href="/assets/images/posts/IAM.png"><img src="/assets/images/posts/IAM_thumb.png" alt="AWS User UI" /></a></p>

<p>###7.  Create API Credentials
Finally create an access key and secret, then set the credentials as environment variables for the Python script. This is explained further in the <a href="https://github.com/pxg/S3-image-compression/blob/develop/readme.md#installation">README</a>.</p>

<p>##Beware Infinite Notification Loops
Notifications are triggered every time a file is updated on S3. Our script monitors for notifications. When we get a notification we compress the associated file and write to S3.</p>

<p>The script gets struck in an infinite loop, as it’s modifying S3 content and therefore triggering notifications. It’s then processing notifications triggered by itself, in a cycle of madness.</p>

<p>##Preventing Infinite Loop Madness</p>

<p>When we receive a notification message about a new or modified file the data looks like this:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="p">{</span><span class="s">'Records'</span><span class="p">:</span> <span class="p">[{</span><span class="s">'awsRegion'</span><span class="p">:</span> <span class="s">'eu-west-1'</span><span class="p">,</span>
              <span class="s">'eventName'</span><span class="p">:</span> <span class="s">'ObjectCreated:Put'</span><span class="p">,</span>
              <span class="s">'eventSource'</span><span class="p">:</span> <span class="s">'aws:s3'</span><span class="p">,</span>
              <span class="s">'eventTime'</span><span class="p">:</span> <span class="s">'2015-07-28T10:14:18.255Z'</span><span class="p">,</span>
              <span class="s">'eventVersion'</span><span class="p">:</span> <span class="s">'2.0'</span><span class="p">,</span>
              <span class="s">'requestParameters'</span><span class="p">:</span> <span class="p">{</span><span class="s">'sourceIPAddress'</span><span class="p">:</span> <span class="s">'37.157.36.218'</span><span class="p">},</span>
              <span class="s">'responseElements'</span><span class="p">:</span> <span class="p">{</span><span class="s">'x-amz-id-2'</span><span class="p">:</span> <span class="s">'lEPwgzy+UXPDRnNCBmHfOzOKtnIJ9ykyvA+MYJwOcsNQrfWjk27xoY2HjMzIpt6TGr6DnW+NBhY='</span><span class="p">,</span>
                                   <span class="s">'x-amz-request-id'</span><span class="p">:</span> <span class="s">'B47FEE01041AE73D'</span><span class="p">},</span>
              <span class="s">'s3'</span><span class="p">:</span> <span class="p">{</span><span class="s">'bucket'</span><span class="p">:</span> <span class="p">{</span><span class="s">'arn'</span><span class="p">:</span> <span class="s">'arn:aws:s3:::pxg-image-resizer'</span><span class="p">,</span>
                                <span class="s">'name'</span><span class="p">:</span> <span class="s">'pxg-image-resizer'</span><span class="p">,</span>
                                <span class="s">'ownerIdentity'</span><span class="p">:</span> <span class="p">{</span><span class="s">'principalId'</span><span class="p">:</span> <span class="s">'A1PWI4M3I9Z57A'</span><span class="p">}},</span>
                     <span class="s">'configurationId'</span><span class="p">:</span> <span class="s">'NotificationObjectCreated'</span><span class="p">,</span>
                     <span class="s">'object'</span><span class="p">:</span> <span class="p">{</span><span class="s">'eTag'</span><span class="p">:</span> <span class="s">'dd34b94d7a954d479febc35a819231b5'</span><span class="p">,</span>
                                <span class="s">'key'</span><span class="p">:</span> <span class="s">'turdus_philomelos.jpg'</span><span class="p">,</span>
                                <span class="s">'size'</span><span class="p">:</span> <span class="mi">251073</span><span class="p">},</span>
                     <span class="s">'s3SchemaVersion'</span><span class="p">:</span> <span class="s">'1.0'</span><span class="p">},</span>
              <span class="s">'userIdentity'</span><span class="p">:</span> <span class="p">{</span><span class="s">'principalId'</span><span class="p">:</span> <span class="s">'AWS:AIDAJ22F5JNYL3GCHHM4O'</span><span class="p">}}]}</span></code></pre></figure>

<p>The import piece of information here is <code class="language-plaintext highlighter-rouge">userIdentity': {'principalId': 'AWS:AIDAJ22F5JNYL3GCHHM4O'}</code> which is related to the AWS user who uploaded the file.</p>

<p>Unfortunately you can’t currently get this user detail within the <a href="https://console.aws.amazon.com/iam/home?region=eu-west-1#users">AWS User Console</a>. However you can run the following code using Boto, the Python AWS library:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">boto</span>
<span class="n">conn</span> <span class="o">=</span> <span class="n">boto</span><span class="p">.</span><span class="n">connect_iam</span><span class="p">()</span>
<span class="n">user_id</span> <span class="o">=</span> <span class="n">conn</span><span class="p">.</span><span class="n">get_user</span><span class="p">().</span><span class="n">user_id</span></code></pre></figure>

<p>Once we have the <code class="language-plaintext highlighter-rouge">user_id</code> we can test it against the value in the message data. This is the reason we added the <code class="language-plaintext highlighter-rouge">getUser</code> policy to the IAM user, without it the code would throw an <code class="language-plaintext highlighter-rouge">AccessDenied</code> error.</p>

<p>On start-up the Python script uses the AWS API to learn it’s own <code class="language-plaintext highlighter-rouge">user_id</code>, it then can ignore messages about updates made by itself, and prevent any infinite loops.</p>

<h2 id="future-work">Future work</h2>
<p>This code is currently meant as a proof of concept and is not yet used in a production system. They are number of things I’d add before running in a production environment:</p>

<ul>
  <li>Logging</li>
  <li>Error handling for corrupted input files</li>
  <li>Error handling of potential mozjpeg crashes</li>
  <li>Support for extra files types (png, gif, etc)</li>
</ul>

<p>A future experiment could be to build on-top of these techniques to process the image files for alternative usages such as a facial recognition system using OpenCV.</p>

<p>This technique could be used to work with different types of file processing, it could be used for text file analysis, or to test SQL dumps are not corrupted.</p>

<p>I plan to do is enhance the code to use threading techniques to compress multiple files concurrently. This will be the subject of a future article.</p>

        <p>
        If you'd like to contact me then you can email <a href="mailto:writing@petegraham.co.uk">writing@petegraham.co.uk</a>.
        </p>
    </section>
    <h2 class="headline">July 29, 2015</h2>
</article>
<footer id="post-meta" class="clearfix">
    <a href='/pr-preview/pr-13/'>
        <img class="avatar" src='/pr-preview/pr-13/assets/images/avatar.png' srcset='/pr-preview/pr-13/assets/images/avatar.png 1x, /pr-preview/pr-13/assets/images/avatar@2x.png 2x'>
        <div>
            <span class="dark">Pete Graham</span>
            <span>Bridging Technology Strategy & Business Scaling</span>
        </div>
    </a>

</footer>

<!-- Disqus comments -->


<!-- Archive post list -->
<!-- TODO: hide current post here -->





  </section>

  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
  <script src='/pr-preview/pr-13/assets/js/main.js'></script>
  <script src='/pr-preview/pr-13/assets/js/highlight.js'></script>
  <script>hljs.initHighlightingOnLoad();</script>

  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-1161798-1', 'auto');
    ga('send', 'pageview');
  </script>
</body>
</html>



